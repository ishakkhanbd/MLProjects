{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "UUb4cfHOer6A"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as T"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "raw_df = pd.read_csv(\"train.csv\")\n",
        "test_df = pd.read_csv(\"test.csv\")\n",
        "#sub_df = pd.read_csv(data_dir+'sample_submission.csv')"
      ],
      "metadata": {
        "id": "B-bxcupcewyr"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_cols = raw_df.columns.tolist()\n",
        "input_cols.remove('label')"
      ],
      "metadata": {
        "id": "GUTVTSprezJx"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_col = 'label'"
      ],
      "metadata": {
        "id": "uehlRfuMe1ep"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for col in input_cols:\n",
        "    raw_df[col] = raw_df[col]/255"
      ],
      "metadata": {
        "id": "I-3ILwIde5p4"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_tensor = torch.tensor(raw_df[input_cols].values, dtype=torch.float32)\n",
        "target_tensor = torch.tensor(raw_df[target_col].values)"
      ],
      "metadata": {
        "id": "XjwNWXAje6RY"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_ds = TensorDataset(input_tensor, target_tensor)"
      ],
      "metadata": {
        "id": "_Jx1Kecwe9CZ"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_sample = raw_ds[100][0].reshape(28, 28)\n",
        "import matplotlib.pyplot as plt\n",
        "print(raw_ds[100][1])\n",
        "plt.imshow(image_sample, cmap='gray')"
      ],
      "metadata": {
        "id": "22YqDlEEe_aH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465
        },
        "outputId": "a4bd00df-8f21-4870-c99c-0638970cd634"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(9)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7aff1e7a27b0>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "random_seed = 42\n",
        "torch.manual_seed(random_seed)"
      ],
      "metadata": {
        "id": "lcGqeTqLfBlg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48177a84-f1b5-4ae9-afcc-3ecea505193f"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7aff03f23770>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_size = 8000\n",
        "train_size = len(raw_ds) - val_size"
      ],
      "metadata": {
        "id": "GftcbhIxfMwY"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 128"
      ],
      "metadata": {
        "id": "fodm-ozSfPNS"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def accurary(output, target):\n",
        "    _, pred = torch.max(output, dim=1)\n",
        "    return torch.tensor(torch.sum(pred==target).item()/len(target))"
      ],
      "metadata": {
        "id": "__6BrBlMfSfR"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BaseModel(nn.Module):\n",
        "    def training_step(self, batch):\n",
        "        images, targets = batch\n",
        "        out = self(images)\n",
        "        loss = F.cross_entropy(out, targets)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch):\n",
        "        images, targets = batch\n",
        "        out = self(images)\n",
        "        loss = F.cross_entropy(out, targets)\n",
        "        acc = accurary(out, targets)\n",
        "        return {'val_loss': loss.detach(), 'val_acc': acc}\n",
        "\n",
        "    def validation_epoch_end(self, outputs):\n",
        "        batch_losses = [x['val_loss'] for x in outputs]\n",
        "        epoch_loss = torch.stack(batch_losses).mean()\n",
        "        batch_accs = [x['val_acc'] for x in outputs]\n",
        "        epoch_acc = torch.stack(batch_accs).mean()\n",
        "        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n",
        "\n",
        "    def epoch_end(self, epoch, result):\n",
        "        print(\"Epoch [{}], val_loss: {:.4f}, val_acc: {:.4f}\".format(epoch, result['val_loss'], result['val_acc']))\n"
      ],
      "metadata": {
        "id": "ewIk-Z_1fUwV"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_default_device():\n",
        "    if torch.cuda.is_available():\n",
        "        return torch.device('cuda')\n",
        "    else:\n",
        "        return torch.device('cpu')\n",
        "\n",
        "def to_device(data, device):\n",
        "    if isinstance(data, (list, tuple)):\n",
        "        return [to_device(x, device) for x in data]\n",
        "    return data.to(device, non_blocking=True)\n",
        "\n",
        "class DeviceDataLoader():\n",
        "    def __init__(self, dl, device):\n",
        "        self.dl = dl\n",
        "        self.device = device\n",
        "\n",
        "    def __iter__(self):\n",
        "        for batch in self.dl:\n",
        "            yield to_device(batch, self.device)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dl)\n",
        "get_default_device()"
      ],
      "metadata": {
        "id": "i-thZIuQfbPJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62b45688-c666-47f8-acd0-d70038e640e8"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_tensor = input_tensor.reshape(-1, 1, 28, 28)\n",
        "\n",
        "raw_ds = TensorDataset(input_tensor, target_tensor)\n",
        "raw_ds[0][0].shape"
      ],
      "metadata": {
        "id": "cMQIIEEZfpIt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c11e0ce-49a5-494c-a46f-0a22835b0b2b"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 28, 28])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_tensor = T.Resize((32, 32))(input_tensor)"
      ],
      "metadata": {
        "id": "Ecvh-m_Ifpto"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_ds = TensorDataset(input_tensor, target_tensor)\n",
        "raw_ds[0][0].shape"
      ],
      "metadata": {
        "id": "TWeZ54XoftH1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_sample = raw_ds[501][0].permute(1, 2, 0)\n",
        "import matplotlib.pyplot as plt\n",
        "print(raw_ds[501][1])\n",
        "plt.imshow(image_sample, cmap='gray')"
      ],
      "metadata": {
        "id": "_ntpXRAufvnF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465
        },
        "outputId": "caa7f95a-764d-4f33-8156-a8f9a5a91bad"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(9)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7afe186f22d0>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds, val_ds = random_split(raw_ds, [train_size, val_size])\n",
        "train_dl = DataLoader(train_ds, batch_size, shuffle=True, num_workers=6, pin_memory=True)\n",
        "val_dl = DataLoader(val_ds, batch_size*2, num_workers=6, pin_memory=True)"
      ],
      "metadata": {
        "id": "GVjwup5Gfxgu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9abd191b-ba3b-454b-f697-bfdebd365457"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dl = DeviceDataLoader(train_dl, get_default_device())\n",
        "val_dl = DeviceDataLoader(val_dl, get_default_device())"
      ],
      "metadata": {
        "id": "5nh3XAj2f2Yx"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def conv_block(in_channels, out_channels, pool=False):\n",
        "    layers = [nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
        "              nn.BatchNorm2d(out_channels),\n",
        "              nn.ReLU(inplace=True)]\n",
        "    if pool:\n",
        "        layers.append(nn.MaxPool2d(2))\n",
        "    return nn.Sequential(*layers)"
      ],
      "metadata": {
        "id": "ZZRM7Aw5f5zo"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CNNModel(BaseModel):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.prep = conv_block(1, 64)\n",
        "        self.layer1 = conv_block(64, 128, pool=True)\n",
        "        self.res1 = nn.Sequential(conv_block(128, 128), conv_block(128, 128))\n",
        "\n",
        "        self.layer2 = conv_block(128, 256, pool=True)\n",
        "        self.layer3 = conv_block(256, 512, pool=True)\n",
        "        self.res2 = nn.Sequential(conv_block(512, 512), conv_block(512, 512))\n",
        "\n",
        "        self.classifier = nn.Sequential(nn.MaxPool2d(4),\n",
        "                                        nn.Flatten(),\n",
        "                                        nn.Dropout(0.2),\n",
        "                                        nn.Linear(512, 10))\n",
        "\n",
        "    def forward(self, xb):\n",
        "        out = self.prep(xb)\n",
        "        out = self.layer1(out)\n",
        "        out = self.res1(out) + out\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.res2(out) + out\n",
        "        out = self.classifier(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "Y03U6Qnsf9_H"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CNNModel()"
      ],
      "metadata": {
        "id": "VdNFTFBzgCYI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7618a852-c21a-455b-86b2-0c294e6cf9c8"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CNNModel(\n",
              "  (prep): Sequential(\n",
              "    (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "  )\n",
              "  (layer1): Sequential(\n",
              "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (res1): Sequential(\n",
              "    (0): Sequential(\n",
              "      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU(inplace=True)\n",
              "    )\n",
              "    (1): Sequential(\n",
              "      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (res2): Sequential(\n",
              "    (0): Sequential(\n",
              "      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU(inplace=True)\n",
              "    )\n",
              "    (1): Sequential(\n",
              "      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (classifier): Sequential(\n",
              "    (0): MaxPool2d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
              "    (1): Flatten(start_dim=1, end_dim=-1)\n",
              "    (2): Dropout(p=0.2, inplace=False)\n",
              "    (3): Linear(in_features=512, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_model = to_device(CNNModel(), get_default_device())"
      ],
      "metadata": {
        "id": "FWOjKfSYgEj4"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def evaluate(model, val_dl):\n",
        "    model.eval()\n",
        "    outputs = [model.validation_step(batch) for batch in val_dl]\n",
        "    return model.validation_epoch_end(outputs)"
      ],
      "metadata": {
        "id": "UMx_DoJPgIQY"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_lr(optimizer):\n",
        "    for param_group in optimizer.param_groups:\n",
        "        return param_group['lr']"
      ],
      "metadata": {
        "id": "iL2CxHsPgKRB"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fit_cnn(epochs, lr, model, train_dl, val_dl, opt_func=torch.optim.SGD,\n",
        "            weight_decay=0,grad_clip=None):\n",
        "    torch.cuda.empty_cache()\n",
        "    history = []\n",
        "    optimizer = opt_func(model.parameters(), lr, weight_decay=weight_decay)\n",
        "    sched = torch.optim.lr_scheduler.OneCycleLR(optimizer, lr, epochs=epochs,\n",
        "                                                steps_per_epoch=len(train_dl))\n",
        "    for epoch in range(epochs):\n",
        "        # Training\n",
        "        model.train()\n",
        "        train_losses = []\n",
        "        for batch in train_dl:\n",
        "            loss = model.training_step(batch)\n",
        "            train_losses.append(loss)\n",
        "            loss.backward()\n",
        "            if grad_clip:\n",
        "                nn.utils.clip_grad_value_(model.parameters(), grad_clip)\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "            sched.step()\n",
        "        # Validation\n",
        "        result = evaluate(model, val_dl)\n",
        "        result['train_loss'] = torch.stack(train_losses).mean().item()\n",
        "        model.epoch_end(epoch, result)\n",
        "        history.append(result)\n",
        "    return history"
      ],
      "metadata": {
        "id": "RrYxH5OZgM4x"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "history = [evaluate(cnn_model, val_dl)]\n",
        "history"
      ],
      "metadata": {
        "id": "RqiL3DQfgR_C",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 480
        },
        "outputId": "90dedee6-54e2-4a73-f4d0-cfd78f8f1da7"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Given input size: (512x3x3). Calculated output size: (512x0x0). Output size is too small",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3850886959.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(model, val_dl)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidation_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_dl\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidation_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2764038973.py\u001b[0m in \u001b[0;36mvalidation_step\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mvalidation_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccurary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1018094453.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, xb)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mres2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    242\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/pooling.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         return F.max_pool2d(\n\u001b[0m\u001b[1;32m    225\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_jit_internal.py\u001b[0m in \u001b[0;36mfn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    625\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mif_true\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 627\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mif_false\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    628\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mif_true\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mif_false\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36m_max_pool2d\u001b[0;34m(input, kernel_size, stride, padding, dilation, ceil_mode, return_indices)\u001b[0m\n\u001b[1;32m    825\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstride\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    826\u001b[0m         \u001b[0mstride\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mannotate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 827\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_pool2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mceil_mode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    828\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    829\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Given input size: (512x3x3). Calculated output size: (512x0x0). Output size is too small"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "history += fit_cnn(15, 0.01, cnn_model, train_dl, val_dl, opt_func=torch.optim.Adam,\n",
        "                   weight_decay=1e-4, grad_clip=0.1)"
      ],
      "metadata": {
        "id": "-Eiqxty4gU11",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "2660b101-d719-4b64-9193-72609f7a8db3"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'history' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_df[input_cols] = test_df[input_cols]/255\n",
        "test_input_tensors = torch.tensor(test_df[input_cols].values, dtype=torch.float32)\n",
        "test_input_tensors = test_input_tensors.reshape(-1, 1, 28, 28)\n",
        "test_input_tensors = T.Resize((32, 32))(test_input_tensors)\n",
        "test_ds = TensorDataset(test_input_tensors)\n",
        "def predict_image(img, model):\n",
        "    xb = to_device(img.unsqueeze(0), get_default_device())\n",
        "    yb = model(xb)\n",
        "    _, preds = torch.max(yb, dim=1)\n",
        "    return preds[0].item()"
      ],
      "metadata": {
        "id": "4g0Eu4EhgX9X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_sample = test_ds[0][0].permute(1, 2, 0)\n",
        "print(predict_image(test_ds[0][0], cnn_model))\n",
        "plt.imshow(image_sample, cmap='gray')"
      ],
      "metadata": {
        "id": "mZxta2A3gdHQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(test_ds)):\n",
        "    sub_df.loc[i, 'Label'] = predict_image(test_ds[i][0], cnn_model)\n",
        "sub_df.to_csv('/kaggle/working/submission.csv', index=False)"
      ],
      "metadata": {
        "id": "1iyrwB-sggLo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}